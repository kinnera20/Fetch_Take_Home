{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378c6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc98505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "users_path = \"users.csv\"  # Replace with actual file path\n",
    "transactions_path = \"transactions.csv\"  # Replace with actual file path\n",
    "products_path = \"products.csv\"  # Replace with actual file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466ff70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   ID            100000 non-null  object\n",
      " 1   CREATED_DATE  100000 non-null  object\n",
      " 2   BIRTH_DATE    96325 non-null   object\n",
      " 3   STATE         95188 non-null   object\n",
      " 4   LANGUAGE      69492 non-null   object\n",
      " 5   GENDER        94108 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "                              ID               CREATED_DATE  \\\n",
      "count                     100000                     100000   \n",
      "unique                    100000                      99942   \n",
      "top     5ef3b4f17053ab141787697d  2023-01-12 18:30:15.000 Z   \n",
      "freq                           1                          2   \n",
      "\n",
      "                       BIRTH_DATE  STATE LANGUAGE  GENDER  \n",
      "count                       96325  95188    69492   94108  \n",
      "unique                      54721     52        2      11  \n",
      "top     1970-01-01 00:00:00.000 Z     TX       en  female  \n",
      "freq                         1272   9028    63403   64240  \n",
      "\n",
      "Sample Data:\n",
      "                         ID               CREATED_DATE  \\\n",
      "0  5ef3b4f17053ab141787697d  2020-06-24 20:17:54.000 Z   \n",
      "1  5ff220d383fcfc12622b96bc  2021-01-03 19:53:55.000 Z   \n",
      "2  6477950aa55bb77a0e27ee10  2023-05-31 18:42:18.000 Z   \n",
      "3  658a306e99b40f103b63ccf8  2023-12-26 01:46:22.000 Z   \n",
      "4  653cf5d6a225ea102b7ecdc2  2023-10-28 11:51:50.000 Z   \n",
      "\n",
      "                  BIRTH_DATE STATE LANGUAGE  GENDER  \n",
      "0  2000-08-11 00:00:00.000 Z    CA   es-419  female  \n",
      "1  2001-09-24 04:00:00.000 Z    PA       en  female  \n",
      "2  1994-10-28 00:00:00.000 Z    FL   es-419  female  \n",
      "3                        NaN    NC       en     NaN  \n",
      "4  1972-03-19 00:00:00.000 Z    PA       en  female  \n"
     ]
    }
   ],
   "source": [
    "# Load and process Users data\n",
    "users = pd.read_csv(users_path)\n",
    "# Initial Dataset Details\n",
    "print(\"Initial Dataset Info:\")\n",
    "print(users.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(users.describe(include='all'))\n",
    "print(\"\\nSample Data:\")\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c46cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# Handle Missing Values\n",
    "# Replace missing values with \"NA\" or appropriate placeholders\n",
    "users['STATE'] = users['STATE'].fillna(\"NA\")\n",
    "users['LANGUAGE'] = users['LANGUAGE'].fillna(\"NA\")\n",
    "users['GENDER'] = users['GENDER'].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83d8190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows based on 'ID': 0\n"
     ]
    }
   ],
   "source": [
    "#Count duplicates\n",
    "duplicate_count = users.duplicated(subset=['ID']).sum()\n",
    "print(f\"\\nNumber of duplicate rows based on 'ID': {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d1bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "users = users.drop_duplicates(subset=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21eae560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Columns\n",
    "users['LANGUAGE'] = users['LANGUAGE'].str.lower()\n",
    "users['GENDER'] = users['GENDER'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a768d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['CREATED_DATE'] = pd.to_datetime(users['CREATED_DATE'], errors='coerce').dt.tz_localize(None) # Remove timezone from datetime64[ns, UTC]\n",
    "users['BIRTH_DATE'] = pd.to_datetime(users['BIRTH_DATE'], errors='coerce').dt.tz_localize(None)  # Ensure no timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a215f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Dates with a Placeholder Date\n",
    "# Using a placeholder date to replace missing or invalid dates (e.g., \"1000-01-01\")\n",
    "\n",
    "# Function to replace invalid dates with a placeholder\n",
    "def replace_invalid_dates(date_column, placeholder_date):\n",
    "    # First, convert to datetime, set errors='coerce' to handle invalid dates\n",
    "    date_column = pd.to_datetime(date_column, errors='coerce', utc=False)\n",
    "    # Replace NaT with the placeholder date\n",
    "    date_column.fillna(pd.to_datetime(placeholder_date), inplace=True)\n",
    "    return date_column\n",
    "\n",
    "# Replace missing or invalid 'CREATED_DATE' and 'BIRTH_DATE' with placeholder date\n",
    "users['CREATED_DATE'] = replace_invalid_dates(users['CREATED_DATE'], '1900-01-01')\n",
    "users['BIRTH_DATE'] = replace_invalid_dates(users['BIRTH_DATE'], '1900-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bdf114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ID            100000 non-null  object        \n",
      " 1   CREATED_DATE  100000 non-null  datetime64[ns]\n",
      " 2   BIRTH_DATE    100000 non-null  datetime64[ns]\n",
      " 3   STATE         100000 non-null  object        \n",
      " 4   LANGUAGE      100000 non-null  object        \n",
      " 5   GENDER        100000 non-null  object        \n",
      "dtypes: datetime64[ns](2), object(4)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "\n",
      "Cleaned Sample Data:\n",
      "                         ID        CREATED_DATE          BIRTH_DATE STATE  \\\n",
      "0  5ef3b4f17053ab141787697d 2020-06-24 20:17:54 2000-08-11 00:00:00    CA   \n",
      "1  5ff220d383fcfc12622b96bc 2021-01-03 19:53:55 2001-09-24 04:00:00    PA   \n",
      "2  6477950aa55bb77a0e27ee10 2023-05-31 18:42:18 1994-10-28 00:00:00    FL   \n",
      "3  658a306e99b40f103b63ccf8 2023-12-26 01:46:22 1900-01-01 00:00:00    NC   \n",
      "4  653cf5d6a225ea102b7ecdc2 2023-10-28 11:51:50 1972-03-19 00:00:00    PA   \n",
      "\n",
      "  LANGUAGE  GENDER  \n",
      "0   es-419  female  \n",
      "1       en  female  \n",
      "2   es-419  female  \n",
      "3       en      na  \n",
      "4       en  female  \n"
     ]
    }
   ],
   "source": [
    "# Post-Cleaning Details\n",
    "print(\"\\nCleaned Dataset Info:\")\n",
    "print(users.info())\n",
    "print(\"\\nCleaned Sample Data:\")\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889241c2",
   "metadata": {},
   "source": [
    "The data cleaning process involved several steps to ensure the quality and consistency of the `Users` dataset. Missing values in the `STATE`, `LANGUAGE`, and `GENDER` columns were replaced with \"NA\" to fill the gaps. Duplicate records based on the `ID` column were identified and removed to ensure uniqueness, and the count of duplicates was logged. The `LANGUAGE` and `GENDER` columns were standardized by converting the text to lowercase to ensure uniformity. Date columns, `CREATED_DATE` and `BIRTH_DATE`, were converted to datetime format while removing timezone information to avoid inconsistencies. Invalid or missing dates were replaced with a placeholder date (\"1900-01-01\") using a custom function to ensure that missing or invalid date values didn't cause issues. Finally, the dataset was reviewed post-cleaning to ensure the changes were applied correctly, and the structure was validated with updated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffb49c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset saved as 'cleaned_users.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "users.to_csv(\"cleaned_users.csv\", index=False)\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_users.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db557b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   RECEIPT_ID      50000 non-null  object \n",
      " 1   PURCHASE_DATE   50000 non-null  object \n",
      " 2   SCAN_DATE       50000 non-null  object \n",
      " 3   STORE_NAME      50000 non-null  object \n",
      " 4   USER_ID         50000 non-null  object \n",
      " 5   BARCODE         44238 non-null  float64\n",
      " 6   FINAL_QUANTITY  50000 non-null  object \n",
      " 7   FINAL_SALE      50000 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "                                  RECEIPT_ID PURCHASE_DATE  \\\n",
      "count                                  50000         50000   \n",
      "unique                                 24440            89   \n",
      "top     bedac253-2256-461b-96af-267748e6cecf    2024-06-15   \n",
      "freq                                      12           774   \n",
      "mean                                     NaN           NaN   \n",
      "std                                      NaN           NaN   \n",
      "min                                      NaN           NaN   \n",
      "25%                                      NaN           NaN   \n",
      "50%                                      NaN           NaN   \n",
      "75%                                      NaN           NaN   \n",
      "max                                      NaN           NaN   \n",
      "\n",
      "                        SCAN_DATE STORE_NAME                   USER_ID  \\\n",
      "count                       50000      50000                     50000   \n",
      "unique                      24440        954                     17694   \n",
      "top     2024-09-08 20:00:42.348 Z    WALMART  64e62de5ca929250373e6cf5   \n",
      "freq                           12      21326                        22   \n",
      "mean                          NaN        NaN                       NaN   \n",
      "std                           NaN        NaN                       NaN   \n",
      "min                           NaN        NaN                       NaN   \n",
      "25%                           NaN        NaN                       NaN   \n",
      "50%                           NaN        NaN                       NaN   \n",
      "75%                           NaN        NaN                       NaN   \n",
      "max                           NaN        NaN                       NaN   \n",
      "\n",
      "             BARCODE FINAL_QUANTITY FINAL_SALE  \n",
      "count   4.423800e+04          50000      50000  \n",
      "unique           NaN             87       1435  \n",
      "top              NaN           1.00             \n",
      "freq             NaN          35698      12500  \n",
      "mean    1.715863e+11            NaN        NaN  \n",
      "std     3.269219e+11            NaN        NaN  \n",
      "min    -1.000000e+00            NaN        NaN  \n",
      "25%     3.077212e+10            NaN        NaN  \n",
      "50%     5.210004e+10            NaN        NaN  \n",
      "75%     8.536765e+10            NaN        NaN  \n",
      "max     9.347108e+12            NaN        NaN  \n",
      "\n",
      "Sample Data:\n",
      "                             RECEIPT_ID PURCHASE_DATE  \\\n",
      "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
      "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
      "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
      "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
      "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
      "\n",
      "                   SCAN_DATE STORE_NAME                   USER_ID  \\\n",
      "0  2024-08-21 14:19:06.539 Z    WALMART  63b73a7f3d310dceeabd4758   \n",
      "1  2024-07-20 09:50:24.206 Z       ALDI  62c08877baa38d1a1f6c211a   \n",
      "2  2024-08-19 15:38:56.813 Z    WALMART  60842f207ac8b7729e472020   \n",
      "3  2024-06-19 11:03:37.468 Z  FOOD LION  63fcd7cea4f8442c3386b589   \n",
      "4  2024-07-05 15:56:43.549 Z   RANDALLS  6193231ae9b3d75037b0f928   \n",
      "\n",
      "        BARCODE FINAL_QUANTITY FINAL_SALE  \n",
      "0  1.530001e+10           1.00             \n",
      "1           NaN           zero       1.49  \n",
      "2  7.874223e+10           1.00             \n",
      "3  7.833997e+11           zero       3.49  \n",
      "4  4.790050e+10           1.00             \n"
     ]
    }
   ],
   "source": [
    "# Load and process transactions data\n",
    "transactions = pd.read_csv(transactions_path)\n",
    "# Initial Dataset Details\n",
    "print(\"Initial Dataset Info:\")\n",
    "print(transactions.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(transactions.describe(include='all'))\n",
    "print(\"\\nSample Data:\")\n",
    "print(transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b3a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "# Replace missing values in categorical columns with \"NA\"\n",
    "transactions['STORE_NAME'] = transactions['STORE_NAME'].fillna(\"NA\")\n",
    "transactions['USER_ID'] = transactions['USER_ID'].fillna(\"NA\")\n",
    "\n",
    "# Replace missing or invalid numeric columns with 0\n",
    "transactions['FINAL_SALE'] = pd.to_numeric(transactions['FINAL_SALE'], errors='coerce').fillna(0)\n",
    "transactions['FINAL_QUANTITY'] = pd.to_numeric(transactions['FINAL_QUANTITY'], errors='coerce').fillna(0)\n",
    "\n",
    "# Replace missing or invalid values in BARCODE with 0 and convert to int\n",
    "transactions['BARCODE'] = transactions['BARCODE'].fillna(0).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac94f97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECEIPT_ID                object\n",
      "PURCHASE_DATE     datetime64[ns]\n",
      "SCAN_DATE         datetime64[ns]\n",
      "STORE_NAME                object\n",
      "USER_ID                   object\n",
      "BARCODE                    int64\n",
      "FINAL_QUANTITY           float64\n",
      "FINAL_SALE               float64\n",
      "dtype: object\n",
      "  PURCHASE_DATE               SCAN_DATE\n",
      "0    2024-08-21 2024-08-21 14:19:06.539\n",
      "1    2024-07-20 2024-07-20 09:50:24.206\n",
      "2    2024-08-18 2024-08-19 15:38:56.813\n",
      "3    2024-06-18 2024-06-19 11:03:37.468\n",
      "4    2024-07-04 2024-07-05 15:56:43.549\n"
     ]
    }
   ],
   "source": [
    "# Function to replace invalid dates with a placeholder\n",
    "def replace_invalid_dates(date_column, placeholder_date):\n",
    "    # Convert to datetime, set errors='coerce' to handle invalid dates\n",
    "    date_column = pd.to_datetime(date_column, errors='coerce')\n",
    "    # Replace NaT with the placeholder date\n",
    "    date_column.fillna(pd.to_datetime(placeholder_date), inplace=True)\n",
    "    # Remove timezone if it exists\n",
    "    return date_column.dt.tz_localize(None)\n",
    "\n",
    "# Replace missing or invalid 'PURCHASE_DATE' and 'SCAN_DATE' with placeholder date and remove timezone\n",
    "transactions['PURCHASE_DATE'] = replace_invalid_dates(transactions['PURCHASE_DATE'], '1900-01-01')\n",
    "transactions['SCAN_DATE'] = replace_invalid_dates(transactions['SCAN_DATE'], '1900-01-01')\n",
    "\n",
    "# Verify changes\n",
    "print(transactions.dtypes)\n",
    "print(transactions[['PURCHASE_DATE', 'SCAN_DATE']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb273d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECEIPT_ID                object\n",
      "PURCHASE_DATE     datetime64[ns]\n",
      "SCAN_DATE         datetime64[ns]\n",
      "STORE_NAME                object\n",
      "USER_ID                   object\n",
      "BARCODE                    int64\n",
      "FINAL_QUANTITY           float64\n",
      "FINAL_SALE               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify changes\n",
    "print(transactions.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25a02e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n"
     ]
    }
   ],
   "source": [
    "# Check for Duplicate Rows\n",
    "# Count duplicate rows\n",
    "duplicate_row_count = transactions.duplicated().sum()\n",
    "print(duplicate_row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba753716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "transactions = transactions.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97df2cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49665 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   RECEIPT_ID      49665 non-null  object        \n",
      " 1   PURCHASE_DATE   49665 non-null  datetime64[ns]\n",
      " 2   SCAN_DATE       49665 non-null  datetime64[ns]\n",
      " 3   STORE_NAME      49665 non-null  object        \n",
      " 4   USER_ID         49665 non-null  object        \n",
      " 5   BARCODE         49665 non-null  int64         \n",
      " 6   FINAL_QUANTITY  49665 non-null  float64       \n",
      " 7   FINAL_SALE      49665 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1), object(3)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "\n",
      "Cleaned Sample Data:\n",
      "                             RECEIPT_ID PURCHASE_DATE               SCAN_DATE  \\\n",
      "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21 2024-08-21 14:19:06.539   \n",
      "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20 2024-07-20 09:50:24.206   \n",
      "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18 2024-08-19 15:38:56.813   \n",
      "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18 2024-06-19 11:03:37.468   \n",
      "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04 2024-07-05 15:56:43.549   \n",
      "\n",
      "  STORE_NAME                   USER_ID       BARCODE  FINAL_QUANTITY  \\\n",
      "0    WALMART  63b73a7f3d310dceeabd4758   15300014978             1.0   \n",
      "1       ALDI  62c08877baa38d1a1f6c211a             0             0.0   \n",
      "2    WALMART  60842f207ac8b7729e472020   78742229751             1.0   \n",
      "3  FOOD LION  63fcd7cea4f8442c3386b589  783399746536             0.0   \n",
      "4   RANDALLS  6193231ae9b3d75037b0f928   47900501183             1.0   \n",
      "\n",
      "   FINAL_SALE  \n",
      "0        0.00  \n",
      "1        1.49  \n",
      "2        0.00  \n",
      "3        3.49  \n",
      "4        0.00  \n"
     ]
    }
   ],
   "source": [
    "#  Post-Cleaning Details\n",
    "print(\"\\nCleaned Dataset Info:\")\n",
    "print(transactions.info())\n",
    "print(\"\\nCleaned Sample Data:\")\n",
    "print(transactions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91038881",
   "metadata": {},
   "source": [
    "The data cleaning process for the `Transactions` dataset involved several key steps to ensure consistency and accuracy. Missing values in categorical columns (`STORE_NAME` and `USER_ID`) were replaced with \"NA\", while missing or invalid numeric columns (`FINAL_SALE`, `FINAL_QUANTITY`) were handled by converting them to numeric values and filling any missing entries with 0. The `BARCODE` column was similarly handled, filling missing values with 0 and converting the data to integers. A custom function was used to replace invalid or missing dates in the `PURCHASE_DATE` and `SCAN_DATE` columns with a placeholder date (\"1900-01-01\") and remove any timezone information. This was done to ensure that the data would not pose any issues when stored or queried in MySQL servers, where timezone inconsistencies can cause errors. Additionally, 335 duplicate rows were identified and removed to ensure the dataset contained only unique records. After cleaning, the data types and structure were verified, ensuring that the dataset was properly formatted and free from inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45ee4cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset saved as 'cleaned_transactions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "transactions.to_csv(\"cleaned_transactions.csv\", index=False)\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_transactions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "459e2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 845552 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   CATEGORY_1    845441 non-null  object \n",
      " 1   CATEGORY_2    844128 non-null  object \n",
      " 2   CATEGORY_3    784986 non-null  object \n",
      " 3   CATEGORY_4    67459 non-null   object \n",
      " 4   MANUFACTURER  619078 non-null  object \n",
      " 5   BRAND         619080 non-null  object \n",
      " 6   BARCODE       841527 non-null  float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 45.2+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "               CATEGORY_1 CATEGORY_2        CATEGORY_3 CATEGORY_4  \\\n",
      "count              845441     844128            784986      67459   \n",
      "unique                 27        121               344        127   \n",
      "top     Health & Wellness      Candy  Confection Candy  Lip Balms   \n",
      "freq               512695     121036             56965       9737   \n",
      "mean                  NaN        NaN               NaN        NaN   \n",
      "std                   NaN        NaN               NaN        NaN   \n",
      "min                   NaN        NaN               NaN        NaN   \n",
      "25%                   NaN        NaN               NaN        NaN   \n",
      "50%                   NaN        NaN               NaN        NaN   \n",
      "75%                   NaN        NaN               NaN        NaN   \n",
      "max                   NaN        NaN               NaN        NaN   \n",
      "\n",
      "                    MANUFACTURER      BRAND       BARCODE  \n",
      "count                     619078     619080  8.415270e+05  \n",
      "unique                      4354       8122           NaN  \n",
      "top     PLACEHOLDER MANUFACTURER  REM BRAND           NaN  \n",
      "freq                       86902      20813           NaN  \n",
      "mean                         NaN        NaN  6.016109e+11  \n",
      "std                          NaN        NaN  1.022530e+12  \n",
      "min                          NaN        NaN  1.850000e+02  \n",
      "25%                          NaN        NaN  7.124923e+10  \n",
      "50%                          NaN        NaN  6.344185e+11  \n",
      "75%                          NaN        NaN  7.683955e+11  \n",
      "max                          NaN        NaN  6.291108e+13  \n",
      "\n",
      "Sample Data:\n",
      "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
      "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
      "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
      "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
      "3  Health & Wellness               Oral Care                   Toothpaste   \n",
      "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
      "\n",
      "  CATEGORY_4                                       MANUFACTURER  \\\n",
      "0        NaN                                                NaN   \n",
      "1        NaN                                                NaN   \n",
      "2        NaN                           PLACEHOLDER MANUFACTURER   \n",
      "3        NaN                                  COLGATE-PALMOLIVE   \n",
      "4        NaN  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
      "\n",
      "             BRAND       BARCODE  \n",
      "0              NaN  7.964944e+11  \n",
      "1              NaN  2.327801e+10  \n",
      "2          ELECSOP  4.618178e+11  \n",
      "3          COLGATE  3.500047e+10  \n",
      "4  MAPLE HOLISTICS  8.068109e+11  \n"
     ]
    }
   ],
   "source": [
    "# Load and process products data\n",
    "products = pd.read_csv(products_path)\n",
    "# Initial Dataset Details\n",
    "print(\"Initial Dataset Info:\")\n",
    "print(products.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(products.describe(include='all'))\n",
    "print(\"\\nSample Data:\")\n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4fa2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "# Replace missing values in categorical columns with \"NA\"\n",
    "categorical_columns = ['CATEGORY_1', 'CATEGORY_2', 'CATEGORY_3', 'CATEGORY_4', 'MANUFACTURER', 'BRAND']\n",
    "products[categorical_columns] = products[categorical_columns].fillna(\"NA\")\n",
    "\n",
    "# Replace missing values in numeric columns with 0\n",
    "numeric_columns = ['BARCODE']\n",
    "products[numeric_columns] = products[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac5c22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "# Check for Duplicate Rows\n",
    "# Count duplicate rows\n",
    "products_duplicate_row_count = products.duplicated().sum()\n",
    "print(products_duplicate_row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddb85cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    796494407820\n",
      "1     23278011028\n",
      "2    461817824225\n",
      "3     35000466815\n",
      "4    806810850459\n",
      "Name: BARCODE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize Data Types\n",
    "# Ensure numeric columns are in numeric format\n",
    "products['BARCODE'] = products['BARCODE'].apply(pd.to_numeric, errors='coerce')  # Convert to numeric\n",
    "products['BARCODE'] = products['BARCODE'].fillna(0).astype(\"int64\")  # Handle NaNs and convert to int64\n",
    "print(products['BARCODE'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eb77921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure categorical columns are strings\n",
    "for col in categorical_columns:\n",
    "    products[col] = products[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88deddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "# Check for Duplicate Rows\n",
    "# Count duplicate rows\n",
    "products_duplicate_row_count = products.duplicated().sum()\n",
    "print(products_duplicate_row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "594b6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "products = products.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2292bb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 845337 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   CATEGORY_1    845337 non-null  object\n",
      " 1   CATEGORY_2    845337 non-null  object\n",
      " 2   CATEGORY_3    845337 non-null  object\n",
      " 3   CATEGORY_4    845337 non-null  object\n",
      " 4   MANUFACTURER  845337 non-null  object\n",
      " 5   BRAND         845337 non-null  object\n",
      " 6   BARCODE       845337 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 51.6+ MB\n",
      "None\n",
      "\n",
      "Cleaned Sample Data:\n",
      "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
      "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
      "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
      "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
      "3  Health & Wellness               Oral Care                   Toothpaste   \n",
      "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
      "\n",
      "  CATEGORY_4                                       MANUFACTURER  \\\n",
      "0         NA                                                 NA   \n",
      "1         NA                                                 NA   \n",
      "2         NA                           PLACEHOLDER MANUFACTURER   \n",
      "3         NA                                  COLGATE-PALMOLIVE   \n",
      "4         NA  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
      "\n",
      "             BRAND       BARCODE  \n",
      "0               NA  796494407820  \n",
      "1               NA   23278011028  \n",
      "2          ELECSOP  461817824225  \n",
      "3          COLGATE   35000466815  \n",
      "4  MAPLE HOLISTICS  806810850459  \n"
     ]
    }
   ],
   "source": [
    "#  Post-Cleaning Details\n",
    "print(\"\\nCleaned Dataset Info:\")\n",
    "print(products.info())\n",
    "print(\"\\nCleaned Sample Data:\")\n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3166d35",
   "metadata": {},
   "source": [
    "The data cleaning process for the `Products` dataset involved several key steps to ensure consistency and accuracy. Missing values in categorical columns (`CATEGORY_1`, `CATEGORY_2`, `CATEGORY_3`, `CATEGORY_4`, `MANUFACTURER`, and `BRAND`) were replaced with \"NA\", while missing values in the numeric column (`BARCODE`) were filled with 0. The dataset was checked for duplicate rows, and 215 duplicate records were identified and removed to ensure uniqueness. Numeric columns, such as `BARCODE`, were converted to a numeric format and handled by filling missing values with 0 and converting the data to `int64`. Additionally, categorical columns were standardized by ensuring all values were stored as strings. After cleaning, the dataset was verified for consistency and structure, ensuring that it was properly formatted and free from issues such as missing values and duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee27f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset saved as 'cleaned_products.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "products.to_csv(\"cleaned_products.csv\", index=False)\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_products.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
